"""
–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ URL –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –¥–ª—è –ø—Ä–æ–≥—Ä–µ–≤–∞
"""
import logging
from typing import List, Dict
from urllib.parse import urlparse

logger = logging.getLogger(__name__)


class URLGrouper:
    """–ì—Ä—É–ø–ø–∏—Ä–æ–≤—â–∏–∫ URL –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –ø—Ä–æ–≥—Ä–µ–≤–∞"""
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –≥—Ä—É–ø–ø—ã 2 (–æ—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã)
    GROUP_2_PATTERNS = [
        '/page/',
        '/blogs/',
        '/blog/',
        '/collection/',
        '/collections/',
        '/catalog/',
        '/category/',
        '/categories/',
    ]
    
    def __init__(self):
        pass
    
    def get_homepage_url(self, domain_name: str) -> str:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ URL –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        
        Args:
            domain_name: –ò–º—è –¥–æ–º–µ–Ω–∞ (example.com)
        
        Returns:
            –ü–æ–ª–Ω—ã–π URL –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã (https://example.com/ –∏–ª–∏ http://example.com/)
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª
        if not domain_name.startswith(('http://', 'https://')):
            # –ü—Ä–æ–±—É–µ–º https –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            homepage = f"https://{domain_name}/"
        else:
            parsed = urlparse(domain_name)
            homepage = f"{parsed.scheme}://{parsed.netloc}/"
        
        return homepage
    
    def is_homepage(self, url: str, domain_name: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URL –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ–π
        
        Args:
            url: –ü—Ä–æ–≤–µ—Ä—è–µ–º—ã–π URL
            domain_name: –ò–º—è –¥–æ–º–µ–Ω–∞
        
        Returns:
            True –µ—Å–ª–∏ —ç—Ç–æ –≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
        """
        parsed = urlparse(url)
        homepage = self.get_homepage_url(domain_name)
        parsed_home = urlparse(homepage)
        
        # –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞: –¥–æ–º–µ–Ω + "/" –∏–ª–∏ –ø—É—Å—Ç–æ–π path
        return (
            parsed.netloc == parsed_home.netloc and
            parsed.path in ['/', '']
        )
    
    def is_group_2_url(self, url: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ URL –∫ –≥—Ä—É–ø–ø–µ 2 (–æ—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã)
        
        Args:
            url: –ü—Ä–æ–≤–µ—Ä—è–µ–º—ã–π URL
        
        Returns:
            True –µ—Å–ª–∏ URL —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≥—Ä—É–ø–ø—ã 2
        """
        url_lower = url.lower()
        return any(pattern in url_lower for pattern in self.GROUP_2_PATTERNS)
    
    def group_urls(self, urls: List[str], domain_name: str) -> Dict[int, List[str]]:
        """
        –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ URL –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        
        Args:
            urls: –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö URL –¥–æ–º–µ–Ω–∞
            domain_name: –ò–º—è –¥–æ–º–µ–Ω–∞
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å {group_id: [urls]}
            - group 1: —Ç–æ–ª—å–∫–æ –≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
            - group 2: –≥–ª–∞–≤–Ω–∞—è + –æ—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (/page, /blogs, /blog, /collection –∏ —Ç.–¥.)
            - group 3: –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        """
        homepage = self.get_homepage_url(domain_name)
        
        # –ì—Ä—É–ø–ø–∞ 1: —Ç–æ–ª—å–∫–æ –≥–ª–∞–≤–Ω–∞—è
        group_1 = []
        
        # –ì—Ä—É–ø–ø–∞ 2: –≥–ª–∞–≤–Ω–∞—è + –æ—Å–Ω–æ–≤–Ω—ã–µ
        group_2 = []
        
        # –ì—Ä—É–ø–ø–∞ 3: –≤—Å–µ
        group_3 = list(urls)
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ URL
        for url in urls:
            if self.is_homepage(url, domain_name):
                group_1.append(url)
                group_2.append(url)
            elif self.is_group_2_url(url):
                group_2.append(url)
        
        # –ï—Å–ª–∏ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –Ω–µ—Ç –≤ —Å–ø–∏—Å–∫–µ, –¥–æ–±–∞–≤–ª—è–µ–º –µ—ë
        if not group_1:
            group_1.append(homepage)
            group_2.insert(0, homepage)
            if homepage not in group_3:
                group_3.insert(0, homepage)
        
        logger.info(
            f"URL grouping for {domain_name}: "
            f"Group 1 (homepage): {len(group_1)}, "
            f"Group 2 (main pages): {len(group_2)}, "
            f"Group 3 (all): {len(group_3)}"
        )
        
        return {
            1: group_1,
            2: group_2,
            3: group_3
        }
    
    def filter_urls_by_group(self, urls: List[str], domain_name: str, group: int) -> List[str]:
        """
        –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è URL –ø–æ –≥—Ä—É–ø–ø–µ
        
        Args:
            urls: –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö URL
            domain_name: –ò–º—è –¥–æ–º–µ–Ω–∞
            group: –ù–æ–º–µ—Ä –≥—Ä—É–ø–ø—ã (1, 2 –∏–ª–∏ 3)
        
        Returns:
            –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ URL –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –≥—Ä—É–ø–ø—ã
        """
        if group not in [1, 2, 3]:
            logger.warning(f"Invalid group {group}, defaulting to group 3")
            return urls
        
        grouped = self.group_urls(urls, domain_name)
        return grouped.get(group, urls)
    
    def get_group_description(self, group: int) -> str:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è –≥—Ä—É–ø–ø—ã
        
        Args:
            group: –ù–æ–º–µ—Ä –≥—Ä—É–ø–ø—ã
        
        Returns:
            –¢–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã
        """
        descriptions = {
            1: "üè† –¢–æ–ª—å–∫–æ –≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞",
            2: "üìÑ –û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–≥–ª–∞–≤–Ω–∞—è + /page, /blogs, /blog, /collection)",
            3: "üåê –í—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–∞–π—Ç–∞"
        }
        return descriptions.get(group, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –≥—Ä—É–ø–ø–∞")
    
    def get_group_stats(self, urls: List[str], domain_name: str) -> Dict[int, int]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –≥—Ä—É–ø–ø–∞–º
        
        Args:
            urls: –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö URL
            domain_name: –ò–º—è –¥–æ–º–µ–Ω–∞
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å {group_id: count}
        """
        grouped = self.group_urls(urls, domain_name)
        return {
            1: len(grouped[1]),
            2: len(grouped[2]),
            3: len(grouped[3])
        }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
url_grouper = URLGrouper()

